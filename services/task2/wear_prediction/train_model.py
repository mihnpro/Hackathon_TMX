import pandas as pd
from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error
import numpy as np



# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
X_train = pd.read_csv('data/splits/X_train.csv')
X_test = pd.read_csv('data/splits/X_test.csv')

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ä—è–¥
y_train = pd.read_csv('data/splits/y_train.csv').squeeze()
y_test = pd.read_csv('data/splits/y_test.csv').squeeze()


# 1. –£–¥–∞–ª–∏ —è–≤–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤ –î–û: {X_train.duplicated().sum()}")
X_train = X_train.drop_duplicates()
y_train = y_train.loc[X_train.index]  # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º
print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤ –ü–û–°–õ–ï: {X_train.duplicated().sum()}")

# 2. –û—Ç—Å–µ–π –≤—ã–±—Ä–æ—Å—ã (–æ—Å—Ç–∞–≤—å 99 –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å)
q99 = y_train.quantile(0.99)
mask = y_train <= q99
X_train = X_train[mask]
y_train = y_train[mask]
print(f"–£–¥–∞–ª–µ–Ω–æ –≤—ã–±—Ä–æ—Å–æ–≤: {(~mask).sum()}")

# 3. –°–æ–∑–¥–∞–π –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
for df in [X_train, X_test]:
    # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–æ–≤
    df['repairs_per_100k'] = df['total_repairs'] / (df['mileage_start'] / 100000 + 1)
    # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ–±—Ç–æ—á–µ–∫
    df['turning_per_100k'] = df['turning_count'] / (df['mileage_start'] / 100000 + 1)
    # –î–æ–ª—è –æ–±—Ç–æ—á–µ–∫
    df['turning_ratio'] = df['turning_count'] / (df['total_repairs'] + 1)

# 4. –†–µ–¥–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ steel_num –æ–±—ä–µ–¥–∏–Ω–∏ –≤ "other"
threshold = 100  # –ú–∏–Ω–∏–º—É–º 100 –ø—Ä–∏–º–µ—Ä–æ–≤
value_counts = X_train['steel_num'].value_counts()
rare_values = value_counts[value_counts < threshold].index
X_train['steel_num'] = X_train['steel_num'].replace(rare_values, 'other')
X_test['steel_num'] = X_test['steel_num'].replace(rare_values, 'other')
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö steel_num –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {X_train['steel_num'].nunique()}")

# ====== –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï steel_num –í –°–¢–†–û–ö–£ ======
print("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ steel_num –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø...")
X_train['steel_num'] = X_train['steel_num'].astype(str).str.replace('.0', '', regex=False).str.strip()
X_test['steel_num'] = X_test['steel_num'].astype(str).str.replace('.0', '', regex=False).str.strip()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
assert len(X_train) == len(y_train), "X_train –∏ y_train —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞!"
assert len(X_test) == len(y_test), "X_test –∏ y_test —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞!"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
print(f"–ü—Ä–æ–ø—É—Å–∫–∏ –≤ X_train: {X_train.isnull().sum().sum()}")
print(f"–ü—Ä–æ–ø—É—Å–∫–∏ –≤ X_test: {X_test.isnull().sum().sum()}")
print(f"–ü—Ä–æ–ø—É—Å–∫–∏ –≤ y_train: {y_train.isnull().sum()}")
print(f"–ü—Ä–æ–ø—É—Å–∫–∏ –≤ y_test: {y_test.isnull().sum()}")

cat_features = ['locomotive_series', 'depo', 'steel_num']


for col in cat_features:
    if col in X_train.columns:
        print(f"  ‚úÖ {col} - {X_train[col].dtype}")
    else:
        print(f"{col} - –ù–ï –ù–ê–ô–î–ï–ù!")



model = CatBoostRegressor(
    iterations=2000,           # –£–≤–µ–ª–∏—á—å
    learning_rate=0.1,        # –£–º–µ–Ω—å—à–∏ (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Ç–æ—á–Ω–µ–µ)
    depth=10,                    # –£–≤–µ–ª–∏—á—å –≥–ª—É–±–∏–Ω—É
    cat_features=cat_features,
    eval_metric='RMSE',
    random_seed=42,
    verbose=100,
    early_stopping_rounds=100,
    l2_leaf_reg=5,              # –£–≤–µ–ª–∏—á—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é
    one_hot_max_size=100,       # –î–ª—è steel_num —Å 7689 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
    bootstrap_type='Bernoulli',
    #subsample=0.7                # –£–º–µ–Ω—å—à–∏ –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
)


model.fit(
    X_train, y_train,
    eval_set=(X_test, y_test),
    plot=False,
    verbose=50
)



# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# –ú–µ—Ç—Ä–∏–∫–∏
mse_train = mean_squared_error(y_train, y_pred_train)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_train = np.sqrt(mse_train)
rmse_test = np.sqrt(mse_test)

print(f"MSE –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {mse_train:.4f}")
print(f"MSE –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ: {mse_test:.4f}")
print(f"RMSE –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {rmse_train:.4f}")
print(f"RMSE –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ: {rmse_test:.4f}")


# –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
print(f"\nüéØ –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (RMSE): {rmse_test:.4f}")
if rmse_test < 0.2:
    print("‚≠ê –û—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å!")
elif rmse_test < 0.3:
    print("üëç –•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å")
elif rmse_test < 0.4:
    print("üëå –ü—Ä–∏–µ–º–ª–µ–º–∞—è –º–æ–¥–µ–ª—å")
else:
    print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω—É–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å")



# –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

# –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç
feature_importance['importance_percent'] = (feature_importance['importance'] / feature_importance['importance'].sum() * 100).round(1)

# –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print("–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for idx, row in feature_importance.head(10).iterrows():
    print(f"  {row['feature']:25} {row['importance']:8.0f} ({row['importance_percent']}%)")